[2022-07-28 14:01:03,408] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: dataquality_pipeline_v5.row_quality_checks.date_check manual__2022-07-28T13:57:40.027582+00:00 [queued]>
[2022-07-28 14:01:03,649] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: dataquality_pipeline_v5.row_quality_checks.date_check manual__2022-07-28T13:57:40.027582+00:00 [queued]>
[2022-07-28 14:01:03,649] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-07-28 14:01:03,649] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-07-28 14:01:03,650] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-07-28 14:01:03,917] {taskinstance.py:1397} INFO - Executing <Task(SnowflakeCheckOperator): row_quality_checks.date_check> on 2022-07-28 13:57:40.027582+00:00
[2022-07-28 14:01:04,029] {standard_task_runner.py:52} INFO - Started process 11389 to run task
[2022-07-28 14:01:04,041] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'dataquality_pipeline_v5', 'row_quality_checks.date_check', 'manual__2022-07-28T13:57:40.027582+00:00', '--job-id', '230', '--raw', '--subdir', 'DAGS_FOLDER/dataquality_pipeline_v5.py', '--cfg-path', '/tmp/tmpx8wbarhr', '--error-file', '/tmp/tmp_0r0nn8b']
[2022-07-28 14:01:04,062] {standard_task_runner.py:80} INFO - Job 230: Subtask row_quality_checks.date_check
[2022-07-28 14:01:04,878] {task_command.py:371} INFO - Running <TaskInstance: dataquality_pipeline_v5.row_quality_checks.date_check manual__2022-07-28T13:57:40.027582+00:00 [running]> on host 2c2de32fb47f
[2022-07-28 14:01:06,201] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=abin404@yopmail.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dataquality_pipeline_v5
AIRFLOW_CTX_TASK_ID=row_quality_checks.date_check
AIRFLOW_CTX_EXECUTION_DATE=2022-07-28T13:57:40.027582+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-28T13:57:40.027582+00:00
[2022-07-28 14:01:06,217] {sql.py:139} INFO - Executing SQL check: -- Template to check various columns in the yellow tripdata data set.
SELECT MIN(date_check)
FROM(
  SELECT
    CASE WHEN dropoff_datetime > pickup_datetime THEN 1 ELSE 0 END AS date_check
  FROM YELLOW_TRIPDATA
)
[2022-07-28 14:01:06,348] {base.py:68} INFO - Using connection ID 'snowflake_default' for task execution.
[2022-07-28 14:01:06,488] {connection.py:262} INFO - Snowflake Connector for Python Version: 2.7.9, Python Version: 3.7.13, Platform: Linux-5.15.0-1014-azure-x86_64-with-debian-11.4
[2022-07-28 14:01:06,489] {connection.py:877} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2022-07-28 14:01:06,489] {connection.py:894} INFO - Setting use_openssl_only mode to False
[2022-07-28 14:01:15,321] {cursor.py:710} INFO - query: [-- Template to check various columns in the yellow tripdata data set. SELECT MIN...]
[2022-07-28 14:01:15,877] {cursor.py:734} INFO - query execution done
[2022-07-28 14:01:15,879] {connection.py:507} INFO - closed
[2022-07-28 14:01:16,138] {connection.py:510} INFO - No async queries seem to be running, deleting session
[2022-07-28 14:01:16,448] {sql.py:142} INFO - Record: (0,)
[2022-07-28 14:01:16,718] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/sql.py", line 146, in execute
    raise AirflowException(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
airflow.exceptions.AirflowException: Test failed.
Query:
-- Template to check various columns in the yellow tripdata data set.
SELECT MIN(date_check)
FROM(
  SELECT
    CASE WHEN dropoff_datetime > pickup_datetime THEN 1 ELSE 0 END AS date_check
  FROM YELLOW_TRIPDATA
)
Results:
(0,)
[2022-07-28 14:01:16,747] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=dataquality_pipeline_v5, task_id=row_quality_checks.date_check, execution_date=20220728T135740, start_date=20220728T140103, end_date=20220728T140116
[2022-07-28 14:01:17,005] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/email.py:119: PendingDeprecationWarning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2022-07-28 14:01:17,006] {email.py:228} INFO - Email alerting: attempt 1
[2022-07-28 14:01:17,484] {email.py:240} INFO - Sent an alert email to ['abin404@yopmail.com']
[2022-07-28 14:01:18,373] {standard_task_runner.py:97} ERROR - Failed to execute job 230 for task row_quality_checks.date_check (Test failed.
Query:
-- Template to check various columns in the yellow tripdata data set.
SELECT MIN(date_check)
FROM(
  SELECT
    CASE WHEN dropoff_datetime > pickup_datetime THEN 1 ELSE 0 END AS date_check
  FROM YELLOW_TRIPDATA
)
Results:
(0,); 11389)
[2022-07-28 14:01:18,434] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-07-28 14:01:18,574] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
